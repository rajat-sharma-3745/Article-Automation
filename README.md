# Article Automation System

A complete end-to-end system for scraping, enhancing, and displaying blog articles using AI. This project automatically fetches articles, improves them using Google search results and LLM rewriting, and displays them in a modern React interface.

## ğŸ¯ Project Overview

This system consists of three main phases:
1. **Phase 1**: Web scraping and CRUD API backend
2. **Phase 2**: AI-powered article enhancement pipeline
3. **Phase 3**: React frontend for article display

Frontend link: https://article-automation.vercel.app \
Backend link: https://article-automate.vercel.app/

---

## ğŸ“Š Architecture Diagram

```mermaid
graph TB
    subgraph "Phase 1: Backend & Scraping"
        A[BeyondChats Blog] -->|Scrape| B[Article Scraper]
        B -->|Store| C[(MongoDB Atlas)]
        C <-->|CRUD| D[Express API]
    end
    
    subgraph "Phase 2: Article Enhancement"
        D -->|Fetch Original| E[Article Updater Script]
        E -->|Search Title| F[Google Search API]
        F -->|Top 2 Results| G[Content Scraper]
        G -->|Extract Content| H[Readability + JSDOM]
        H -->|Original + References| I[Gemini LLM]
        I -->|Enhanced Article| J[Update via API]
        J -->|Save| C
    end
    
    subgraph "Phase 3: Frontend"
        D -->|Fetch All| K[React Frontend]
        K -->|Display| L[Article Grid]
        L -->|Click| M[Article Detail View]
        M -->|Show| N[Original + Enhanced Content]
    end
```

---

## ğŸ”„ Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PHASE 1: SCRAPING                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  BeyondChats Blog (Last Pages)        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Article Scraper     â”‚
                        â”‚   â€¢ Find last page    â”‚
                        â”‚   â€¢ Scrape metadata   â”‚
                        â”‚   â€¢ Fetch full contentâ”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚         MongoDB Atlas                 â”‚
            â”‚  Articles Collection:                 â”‚
            â”‚  â€¢ title, url, author, date           â”‚
            â”‚  â€¢ description, image, tags           â”‚
            â”‚  â€¢ content (scraped),updatedContnt    â”‚
            â”‚  â€¢ status: "original"                 â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚      Express CRUD API                 â”‚
            â”‚  GET    /api/articles                 â”‚
            â”‚  GET    /api/articles/:id             â”‚
            â”‚  POST   /api/articles/scrape          â”‚
            â”‚  PUT    /api/articles/:id             â”‚
            â”‚  DELETE /api/articles/:id             â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 2: AI ENHANCEMENT                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Article Updater Script              â”‚
            â”‚   (Automated Enhancement Pipeline)    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚               â”‚               â”‚
                    â–¼               â–¼               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Fetch Original  â”‚ â”‚Google Search â”‚ â”‚Content Scraper â”‚
        â”‚ Articles from   â”‚ â”‚API (Title)   â”‚ â”‚(Top 2 Results) â”‚
        â”‚ MongoDB         â”‚ â”‚              â”‚ â”‚                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚               â”‚               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Gemini LLM API       â”‚
                        â”‚  Prompt:              â”‚
                        â”‚  â€¢ Original article   â”‚
                        â”‚  â€¢ Reference 1        â”‚
                        â”‚  â€¢ Reference 2        â”‚
                        â”‚  â†’ Rewrite & enhance  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Updated Article      â”‚
                        â”‚  â€¢ updatedContent     â”‚
                        â”‚  â€¢ status: "updated"  â”‚
                        â”‚  â€¢ references[]       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    PUT /api/articles/:id              â”‚
            â”‚    Save to MongoDB                    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PHASE 3: FRONTEND                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚        React Frontend (Vite)          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚               â”‚               â”‚
                    â–¼               â–¼               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Fetch Articles â”‚ â”‚ Article Grid â”‚ â”‚ Article Detail â”‚
        â”‚  from API       â”‚ â”‚ View         â”‚ â”‚ Modal          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚               â”‚               â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Display:            â”‚
                        â”‚   â€¢ Original content  â”‚
                        â”‚   â€¢ Enhanced content  â”‚
                        â”‚   â€¢ References        â”‚
                        â”‚   â€¢ Metadata          â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Technology Stack

### Phase 1: Backend
- **Runtime**: Node.js
- **Framework**: Express.js
- **Database**: MongoDB Atlas
- **Scraping**: Axios, Cheerio, @mozilla/readability, jsdom
- **ODM**: Mongoose

### Phase 2: Enhancement Script
- **Search**: Google Custom Search API
- **Content Extraction**: Readability, JSDOM
- **AI**: Google Gemini API
- **HTTP Client**: Axios

### Phase 3: Frontend
- **Framework**: React 18
- **Build Tool**: Vite
- **Styling**: Tailwind CSS
- **Routing**: React Router DOM
- **Markdown**: react-markdown, remark-gfm
- **Syntax Highlighting**: react-syntax-highlighter
- **Icons**: lucide-react

---

## ğŸ“ Project Structure

```
article-automation/
â”œâ”€â”€ Article-scraping-backend/      # Phase 1: Backend API
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ server.js
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â””â”€â”€ db.js
â”‚   â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”‚   â””â”€â”€ article.controller.js
â”‚   â”‚   â”œâ”€â”€ middlewares/
â”‚   â”‚   â”‚   â””â”€â”€ error.js
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ Article.js
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ article.routes.js
â”‚   â”‚   â”‚   â””â”€â”€ scrape.routes.js
â”‚   â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”‚   â””â”€â”€ article.scraper.js
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ asyncHandler.js
â”‚   â”‚       â””â”€â”€ errorHandler.js
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ article-updater-script/        # Phase 2: Enhancement Pipeline
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.js
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ articleFetcher.js
â”‚   â”‚       â”œâ”€â”€ articleUpdate.js
â”‚   â”‚       â”œâ”€â”€ contentScraper.js
â”‚   â”‚       â”œâ”€â”€ googleSearch.js
â”‚   â”‚       â””â”€â”€ llmRewriter.js
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ frontend/                      # Phase 3: React UI
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ App.jsx
    â”‚   â”œâ”€â”€ main.jsx
    â”‚   â”œâ”€â”€ api/
    â”‚   â”‚   â””â”€â”€ article.api.js
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ ArticleCard.jsx
    â”‚   â”‚   â”œâ”€â”€ ArticleDetail.jsx
    â”‚   â”‚   â”œâ”€â”€ MarkdownRenderer.jsx
    â”‚   â”‚   â””â”€â”€ Navbar.jsx
    â”‚   â””â”€â”€ pages/
    â”‚       â””â”€â”€ ArticlesPage.jsx
    â””â”€â”€ package.json
```

---

## ğŸš€ Local Setup Instructions

### Prerequisites

- **Node.js**: v18+ ([Download](https://nodejs.org/))
- **MongoDB Atlas Account**: ([Sign up](https://www.mongodb.com/cloud/atlas/register))
- **API Keys** (see API Setup section below)

---

### Phase 1: Backend Setup

1. **Navigate to backend directory**
   ```bash
   cd Article-scraping-backend
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Create `.env` file**
   ```bash
   PORT=3000
   MONGO_URI=your_mongodb_atlas_connection_string
   ```

4. **Start the server**
   ```bash
   npm start
   ```
   
   Server will run on `http://localhost:3000`

5. **Scrape initial articles** (Optional)
   ```bash
   # Send POST request to scrape articles
   curl -X POST http://localhost:3000/api/articles/scrape \
     -H "Content-Type: application/json" \
     -d '{"count": 5}'
   ```

---

### Phase 2: Enhancement Script Setup

1. **Navigate to script directory**
   ```bash
   cd article-updater-script
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Create `.env` file**
   ```bash
   API_BASE_URL=http://localhost:3000/api
   GOOGLE_API_KEY=your_google_api_key
   GOOGLE_CX=your_search_engine_id
   GEMINI_API_KEY=your_gemini_api_key
   ```

4. **Run the enhancement script**
   ```bash
   npm start
   ```
   
   This will:
   - Fetch all original articles
   - Search Google for each title
   - Scrape top 2 results
   - Rewrite using Gemini AI
   - Update articles in database

---

### Phase 3: Frontend Setup

1. **Navigate to frontend directory**
   ```bash
   cd frontend
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Create `.env` file**
   ```bash
   VITE_API_BASE_URL=http://localhost:3000/api
   ```

4. **Start development server**
   ```bash
   npm run dev
   ```
   
   Frontend will run on `http://localhost:5173`

---

## ğŸ”‘ API Keys Setup

### 1. MongoDB Atlas Connection String

1. Go to [MongoDB Atlas](https://www.mongodb.com/cloud/atlas)
2. Create a cluster (free tier available)
3. Click "Connect" â†’ "Connect your application"
4. Copy connection string
5. Replace `<password>` with your database user password
6. Add to `.env` as `MONGO_URI`

**Format**: `mongodb+srv://username:password@cluster.mongodb.net/database?retryWrites=true&w=majority`

---

### 2. Google Custom Search API

**Setup Steps**:

1. **Get API Key**:
   - Go to [Google Cloud Console](https://console.cloud.google.com/)
   - Create a new project or select existing
   - Enable "Custom Search API"
   - Go to "Credentials" â†’ "Create Credentials" â†’ "API Key"
   - Copy the API key

2. **Create Custom Search Engine**:
   - Go to [Programmable Search Engine](https://programmablesearchengine.google.com/)
   - Click "Add" to create new search engine
   - In "Sites to search": Select "Search the entire web"
   - Create and get your Search Engine ID (cx)

**Cost**: Free tier includes 100 queries/day

**Add to `.env`**:
```
GOOGLE_API_KEY=AIzaSyXXXXXXXXXXXXXXXXXXXXXXXXX
GOOGLE_CX=your_search_engine_id
```

---

### 3. Google Gemini API

**Setup Steps**:

1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Click "Create API Key"
3. Copy the generated key

**Cost**: Free tier includes:
- 15 requests per minute
- 1 million tokens per minute
- 1,500 requests per day

**Add to `.env`**:
```
GEMINI_API_KEY=AIzaSyXXXXXXXXXXXXXXXXXXXXXXXXX
```

---

## ğŸ® Usage Guide

### Step 1: Start Backend
```bash
cd Article-scraping-backend
npm start
```

### Step 2: Scrape Initial Articles
Visit `http://localhost:3000/api/articles/scrape` via POST request or use:
```bash
curl -X POST http://localhost:3000/api/articles/scrape -H "Content-Type: application/json" -d '{"count": 5}'
```

### Step 3: Run Enhancement Script
```bash
cd article-updater-script
npm start
```
Wait for the script to complete (may take 5-10 minutes depending on article count)

### Step 4: Start Frontend
```bash
cd frontend
npm run dev
```
Open `http://localhost:5173` in your browser

---

## ğŸ“¡ API Endpoints

### Articles API

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/articles` | Get all articles  |
| GET | `/api/articles/:id` | Get single article by ID |
| POST | `/api/articles/scrape` | Trigger scraping (body: `{count: 5}`) |
| PUT | `/api/articles/:id` | Update article by ID |
| DELETE | `/api/articles/:id` | Delete article by ID |

---

## ğŸ—„ï¸ Database Schema

```javascript
{
  title: String,           // Article title
  url: String,             // Original article URL
  author: String,          // Article author
  date: String,            // Publication date
  description: String,     // Full scraped content
  image: String,           // Featured image URL
  tags: [String],          // Article tags
  updatedContent: String,  // AI-enhanced content (Phase 2)
  status: String,          // "original" | "updated"
  references: [{           // Reference articles (Phase 2)
    title: String,
    url: String
  }],
  createdAt: Date,         // Auto-generated
  updatedAt: Date          // Auto-generated
}
```

---

## ğŸ¨ Frontend Features

- âœ… Responsive grid layout
- âœ… Article cards with metadata
- âœ… Click to view full details
- âœ… Side-by-side original vs enhanced content
- âœ… Markdown rendering with syntax highlighting
- âœ… Copy to clipboard functionality
- âœ… External link to original source
- âœ… Reference citations at bottom
- âœ… Status badges (Original/Updated)
- âœ… Tags display
- âœ… Loading states
- âœ… Error handling

---

##  Troubleshooting

### Enhancement Script Issues

**Problem**: Google Search API quota exceeded
```
Solution: Wait 24 hours or upgrade to paid tier
- Free tier: 100 queries/day
- Check usage: https://console.cloud.google.com/
```

**Problem**: Gemini API rate limit
```
Solution: Add delays between requests or use different API key
- Free tier: 15 requests/minute
- Script includes automatic delays
```

**Problem**: Content scraping fails
```
Solution: Some websites block scrapers
- Script will skip and continue to next article
- Check console for specific errors
```

---



### API Rate Limits
| Service | Free Tier | Our Usage |
|---------|-----------|-----------|
| Google Search | 100/day | 2 per article |
| Gemini API | 1500/day | 1 per article |

---

## Important Notes

1. **Rate Limiting**: The enhancement script includes delays to respect API rate limits
2. **Costs**: All APIs used have generous free tiers sufficient for development
3. **Content Rights**: Scraped content is for educational purposes only
4. **Error Handling**: Scripts will skip problematic articles and continue

---


## Development Notes

### Adding More Articles
```bash
# Scrape more articles from BeyondChats
curl -X POST http://localhost:3000/api/articles/scrape \
  -H "Content-Type: application/json" \
  -d '{"count": 10}'
```

### Re-running Enhancement
```bash
# Delete all enhanced content to re-process
# Or manually update status to "original" in database
cd article-updater-script
npm start
```



